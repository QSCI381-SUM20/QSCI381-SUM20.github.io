---
title: "Lab 05"
subtitle: "*Sampling Distributions*"
author: ""
institute: ""
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["style.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
 
---     
class: middle

In this lab, we'll practice carrying out hypothesis tests in `R`.

---
class: middle

#### Scatterplot

temp <- nycflights13::flights %>% filter(month == 7 & day == 15)

---
class: middle

#### Linear regression by hand
---
class: middle

#### Linear regression in R
---
class: middle

#### Summarizing results
---
class: middle

#### Interpreting results
---
class: middle

#### Predicts
---
class: middle

#### Residual plots
---
class: middle

#### linear regression plots
---
class: middle

#### SAT Scores
---

class: middle

#### SAT Scores

Suppose we have data on 30 students' changes in SAT scores after taking an SAT class and we want to figure out how much the class helped.

What might be a good population parameter? What would be a good sample statistic?

```{r, message = F, warning = F}
library(openintro)
data("sat.improve")
sat.improve$sat_improve
```

---
class: middle

#### SAT Scores

Let's compute the sample mean.

```{r, message = F, warning = F}
mu_hat <- mean(sat.improve$sat_improve)
mu_hat
```

Is this evidence that the class helped?
---

class: middle

#### One-sample t interval

Let's compute a 95% t interval:

```{r, message = F, warning = F}
n <- length(sat.improve$sat_improve)
se_mu_hat <- sd(sat.improve$sat_improve) / sqrt(n)
se_mu_hat

# 95% t-interval
upper_bound <- mu_hat + qt(.975, df = n - 1) * se_mu_hat
lower_bound <- mu_hat - qt(.975, df = n - 1) * se_mu_hat
c(lower_bound, upper_bound)
```

Is this evidence that the class helped?
---
class: middle

#### One-sample t interval

Let's compute a **90%** t interval:

```{r, message = F, warning = F}
n <- length(sat.improve$sat_improve)
se_mu_hat <- sd(sat.improve$sat_improve) / sqrt(n)
se_mu_hat

# 90% t-interval
upper_bound <- mu_hat + qt(.95, df = n - 1) * se_mu_hat
lower_bound <- mu_hat - qt(.95, df = n - 1) * se_mu_hat
c(lower_bound, upper_bound)
```

---
class: middle

#### One-sample t interval

Let's compute an **80%** t interval:

```{r, message = F, warning = F}
n <- length(sat.improve$sat_improve)
se_mu_hat <- sd(sat.improve$sat_improve) / sqrt(n)
se_mu_hat

# 80% t-interval
upper_bound <- mu_hat + qt(.90, df = n - 1) * se_mu_hat
lower_bound <- mu_hat - qt(.90, df = n - 1) * se_mu_hat
c(lower_bound, upper_bound)
```

---
class: middle

#### One-sample t interval

Note that since $n$ is pretty large $(n = 30)$, our sampling distribution is almost normal:

```{r, message = F, warning = F, echo = F, fig.width = 8, fig.height = 6, fig.align = "center"}
x <- seq(-4, 4, length.out = 1000)
n <- dnorm(x)
t <- dt(x, df = 29)
plot(x, n, type = 'l', frame.plot = F, axes = F,
     ylab = '', lwd = 2)
lines(x, t, col = 'tomato', add = T, lwd = 2)
legend("topright", c("normal", "t"), lty  =1, col = c("black", "tomato"), 
       bty = 'n')
```
---
class: middle 

#### One-sample t test for means

What are appropriate test hypotheses if we want to see if the class really helped? 

What level of significance should we choose? By default usually $\alpha = 0.05$

---

class: middle 

#### One sided one-sample t test for means

** $H_0: \mu = 0\hspace{5ex} H_A:\mu>0$ **

```{r, message = F, warning = F}
# 1. calculate sample statistic
mu_hat = mean(sat.improve$sat_improve)

# 2. compute standard error
n <- length(sat.improve$sat_improve)
se_mu_hat <- sd(sat.improve$sat_improve) / sqrt(n)

# 3. compute t-statistic
t = (mu_hat - 0) / se_mu_hat
t
```
---
class: middle 

#### One sided one-sample t test for means

** $H_0: \mu = 0\hspace{5ex} H_A:\mu>0$ **

Draw a picture: 
```{r, message = F, warning = F, echo = F, fig.width = 6, fig.height = 4, fig.align = "center"}
x <- seq(-4, 4, length.out = 1000)
t <- dt(x, df = 29)
plot(x, t, type = 'l', frame.plot = F, axes = F,
     ylab = '', col = 'tomato', lwd = 2)
polygon(x = c(1.8, x[x >= 1.8]), y = c(0, t[x >= 1.8]), col = 'tomato',border = NA)
```

---
class: middle 

#### One sided one-sample t test for means

** $H_0: \mu = 0\hspace{5ex} H_A:\mu>0$ **

Draw a picture: 
```{r, message = F, warning = F, echo = F, fig.width = 4, fig.height = 3, fig.align = "center"}
x <- seq(-4, 4, length.out = 1000)
t <- dt(x, df = 29)
plot(x, t, type = 'l', frame.plot = F, axes = F,
     ylab = '', col = 'tomato', lwd = 2)
polygon(x = c(1.8, x[x >= 1.8]), y = c(0, t[x >= 1.8]), col = 'tomato',border = NA)
```
```{r, message = F, warning = F}
t = (mu_hat - 0) / se_mu_hat
# 4. calculate p-value
upper_tail_prob <- 1 - pt(t, df = n - 1)
upper_tail_prob
```
---
class: middle 

#### One sided one-sample t test for means

Thus at $\alpha = 0.05$, we reject the null hypothesis.


---
class: middle 
#### Two sided one-sample t test for means

How do we compute a two-sided p-value?

** $H_0: \mu = 0\hspace{5ex} H_A:\mu\not=0$ **

Draw a picture: 
```{r, message = F, warning = F, echo = F, fig.width = 4, fig.height = 3, fig.align = "center"}
x <- seq(-4, 4, length.out = 1000)
t <- dt(x, df = 29)
plot(x, t, type = 'l', frame.plot = F, axes = F,
     ylab = '', col = 'tomato', lwd = 2)
polygon(x = c(1.8, x[x >= 1.8]), y = c(0, t[x >= 1.8]), col = 'tomato',border = NA)
polygon(x = c(x[x <= -1.8], -1.8), y = c(t[x <= -1.8], 0), col = 'tomato',border = NA)
```
---
class: middle 
#### Two sided one-sample t test for means

How do we compute a two-sided p-value?

** $H_0: \mu = 0\hspace{5ex} H_A:\mu\not=0$ **

We can just multiply our one-sided p-value by two, or we can use R: 
```{r, message = F, warning = F}
t = (mu_hat - 0) / se_mu_hat
# 4. calculate p-value
upper_tail_prob <- 1 - pt(t, df = n - 1)
upper_tail_prob

two_sided_p_value <- upper_tail_prob * 2
two_sided_p_value

two_sided_p_value <- (1 - pt(t, df = n - 1)) + pt(-t, df = n - 1)
two_sided_p_value
```
---
class: middle 
#### Two sided one-sample t test for means

If we don't want to do this by hand, we can also use the `t.test` function:

** $H_0: \mu = 0\hspace{5ex} H_A:\mu\not=0$ **

```{r, message = F, warning = F}
# two-sided test
t.test(sat.improve$sat_improve)
```
---
class: middle 
#### one sided one-sample t test for means

If we don't want to do this by hand, we can also use the `t.test` function:

** $H_0: \mu = 0\hspace{5ex} H_A:\mu<0$ **

```{r, message = F, warning = F}
# two-sided test
t.test(sat.improve$sat_improve, alternative = "greater")
```

---
class: middle 
#### Two sided one-sample t test for means

`t.test` assumes the null hypothesis has $\mu=0$, but we can set other values as well:

** $H_0: \mu = 50\hspace{5ex} H_A:\mu\not=50$ **

```{r, message = F, warning = F}
# two-sided test
t.test(sat.improve$sat_improve, mu = 50)
```

---
class: middle 
#### Hypothesis test for proportions

What if instead, we performed a hypothesis test about $p$, the proportion of students who improved?

** $H_0: p = 0.5\hspace{5ex} H_A:p >0.5$ **
```{r, message = F, warning = F}
# 1. calculate sample statistic
p_hat <- mean(sat.improve$sat_improve > 0)
p_hat 

# 2. compute standard error
n <- length(sat.improve$sat_improve)
se_p_hat <- sqrt(p_hat * (1 - p_hat) / n)

# 3. compute t-statistic
z = (p_hat - 0.5) / se_p_hat
z
```
---
class: middle 
#### One-sided hypothesis test for proportions
** $H_0: p = 0.5\hspace{5ex} H_A:p >0.5$ **

Draw a picture: 
```{r, message = F, warning = F, echo = F, fig.width = 4, fig.height = 3, fig.align = "center"}
x <- seq(-4, 4, length.out = 1000)
t <- dt(x, df = 29)
plot(x, t, type = 'l', frame.plot = F, axes = F,
     ylab = '', col = 'tomato', lwd = 2)
polygon(x = c(1.8, x[x >= 1.8]), y = c(0, t[x >= 1.8]), col = 'tomato',border = NA)
```

```{r, message = F, warning = F}
z = (p_hat - 0.5) / se_p_hat
# 4. calculate p-value
upper_tail_prob <- 1 - pnorm(z)
upper_tail_prob
```

---
class: middle 
#### Hypothesis test for proportions

What just happened?

The p-value is so small that R thinks it is essentially 0. 
---

class: middle 
#### 80% confidence interval for proportions

```{r, message = F, warning = F}

# 80% z-interval
upper_bound <- p_hat + qnorm(.90) * se_p_hat
lower_bound <- p_hat - qnorm(.90) * se_p_hat
c(lower_bound, upper_bound)
```
---
class: middle 
#### 95% confidence interval for proportions

```{r, message = F, warning = F}

# 95% z-interval
upper_bound <- p_hat + qnorm(.975) * se_p_hat
lower_bound <- p_hat - qnorm(.975) * se_p_hat
c(lower_bound, upper_bound)
```
---
class: middle 
#### 95% confidence interval for proportions
What just happened?

We tried to use the central limit theorem without checking to see if our sample size was big enough! We need $n\hat{p}\geq 10$ and $n(1-\hat{p})\geq 10$. Which isn't satisfied? 
---