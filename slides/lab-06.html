<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lab 05</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <meta name="date" content="2020-07-22" />
    <link rel="stylesheet" href="style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Lab 05
## <em>Sampling Distributions</em>
### 2020-07-22

---

class: middle

In this lab, we'll practice carrying out hypothesis tests in `R`.

---
class: middle

#### Scatterplot

temp &lt;- nycflights13::flights %&gt;% filter(month == 7 &amp; day == 15)

---
class: middle

#### Linear regression by hand
---
class: middle

#### Linear regression in R
---
class: middle

#### Summarizing results
---
class: middle

#### Interpreting results
---
class: middle

#### Predicts
---
class: middle

#### Residual plots
---
class: middle

#### linear regression plots
---
class: middle

#### SAT Scores
---

class: middle

#### SAT Scores

Suppose we have data on 30 students' changes in SAT scores after taking an SAT class and we want to figure out how much the class helped.

What might be a good population parameter? What would be a good sample statistic?


```r
library(openintro)
data("sat.improve")
sat.improve$sat_improve
```

```
##  [1]  57 133 231  41 114 129 170 103 259 110 149 189  93  47 245 -42 182
## [18] 123 191 150 266  36 231 257 120 -52 153  78 175 140
```

---
class: middle

#### SAT Scores

Let's compute the sample mean.


```r
mu_hat &lt;- mean(sat.improve$sat_improve)
mu_hat
```

```
## [1] 135.9333
```

Is this evidence that the class helped?
---

class: middle

#### One-sample t interval

Let's compute a 95% t interval:


```r
n &lt;- length(sat.improve$sat_improve)
se_mu_hat &lt;- sd(sat.improve$sat_improve) / sqrt(n)
se_mu_hat
```

```
## [1] 15.01179
```

```r
# 95% t-interval
upper_bound &lt;- mu_hat + qt(.975, df = n - 1) * se_mu_hat
lower_bound &lt;- mu_hat - qt(.975, df = n - 1) * se_mu_hat
c(lower_bound, upper_bound)
```

```
## [1] 105.2308 166.6359
```

Is this evidence that the class helped?
---
class: middle

#### One-sample t interval

Let's compute a **90%** t interval:


```r
n &lt;- length(sat.improve$sat_improve)
se_mu_hat &lt;- sd(sat.improve$sat_improve) / sqrt(n)
se_mu_hat
```

```
## [1] 15.01179
```

```r
# 90% t-interval
upper_bound &lt;- mu_hat + qt(.95, df = n - 1) * se_mu_hat
lower_bound &lt;- mu_hat - qt(.95, df = n - 1) * se_mu_hat
c(lower_bound, upper_bound)
```

```
## [1] 110.4264 161.4403
```

---
class: middle

#### One-sample t interval

Let's compute an **80%** t interval:


```r
n &lt;- length(sat.improve$sat_improve)
se_mu_hat &lt;- sd(sat.improve$sat_improve) / sqrt(n)
se_mu_hat
```

```
## [1] 15.01179
```

```r
# 80% t-interval
upper_bound &lt;- mu_hat + qt(.90, df = n - 1) * se_mu_hat
lower_bound &lt;- mu_hat - qt(.90, df = n - 1) * se_mu_hat
c(lower_bound, upper_bound)
```

```
## [1] 116.2464 155.6203
```

---
class: middle

#### One-sample t interval

Note that since `\(n\)` is pretty large `\((n = 30)\)`, our sampling distribution is almost normal:

&lt;img src="lab-06_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;
---
class: middle 

#### One-sample t test for means

What are appropriate test hypotheses if we want to see if the class really helped? 

What level of significance should we choose? By default usually `\(\alpha = 0.05\)`

---

class: middle 

#### One sided one-sample t test for means

** `\(H_0: \mu = 0\hspace{5ex} H_A:\mu&gt;0\)` **


```r
# 1. calculate sample statistic
mu_hat = mean(sat.improve$sat_improve)

# 2. compute standard error
n &lt;- length(sat.improve$sat_improve)
se_mu_hat &lt;- sd(sat.improve$sat_improve) / sqrt(n)

# 3. compute t-statistic
t = (mu_hat - 0) / se_mu_hat
t
```

```
## [1] 9.055104
```
---
class: middle 

#### One sided one-sample t test for means

** `\(H_0: \mu = 0\hspace{5ex} H_A:\mu&gt;0\)` **

Draw a picture: 
&lt;img src="lab-06_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

---
class: middle 

#### One sided one-sample t test for means

** `\(H_0: \mu = 0\hspace{5ex} H_A:\mu&gt;0\)` **

Draw a picture: 
&lt;img src="lab-06_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;

```r
t = (mu_hat - 0) / se_mu_hat
# 4. calculate p-value
upper_tail_prob &lt;- 1 - pt(t, df = n - 1)
upper_tail_prob
```

```
## [1] 2.983819e-10
```
---
class: middle 

#### One sided one-sample t test for means

Thus at `\(\alpha = 0.05\)`, we reject the null hypothesis.


---
class: middle 
#### Two sided one-sample t test for means

How do we compute a two-sided p-value?

** `\(H_0: \mu = 0\hspace{5ex} H_A:\mu\not=0\)` **

Draw a picture: 
&lt;img src="lab-06_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;
---
class: middle 
#### Two sided one-sample t test for means

How do we compute a two-sided p-value?

** `\(H_0: \mu = 0\hspace{5ex} H_A:\mu\not=0\)` **

We can just multiply our one-sided p-value by two, or we can use R: 

```r
t = (mu_hat - 0) / se_mu_hat
# 4. calculate p-value
upper_tail_prob &lt;- 1 - pt(t, df = n - 1)
upper_tail_prob
```

```
## [1] 2.983819e-10
```

```r
two_sided_p_value &lt;- upper_tail_prob * 2
two_sided_p_value
```

```
## [1] 5.967637e-10
```

```r
two_sided_p_value &lt;- (1 - pt(t, df = n - 1)) + pt(-t, df = n - 1)
two_sided_p_value
```

```
## [1] 5.967637e-10
```
---
class: middle 
#### Two sided one-sample t test for means

If we don't want to do this by hand, we can also use the `t.test` function:

** `\(H_0: \mu = 0\hspace{5ex} H_A:\mu\not=0\)` **


```r
# two-sided test
t.test(sat.improve$sat_improve)
```

```
## 
## 	One Sample t-test
## 
## data:  sat.improve$sat_improve
## t = 9.0551, df = 29, p-value = 5.968e-10
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  105.2308 166.6359
## sample estimates:
## mean of x 
##  135.9333
```
---
class: middle 
#### one sided one-sample t test for means

If we don't want to do this by hand, we can also use the `t.test` function:

** `\(H_0: \mu = 0\hspace{5ex} H_A:\mu&lt;0\)` **


```r
# two-sided test
t.test(sat.improve$sat_improve, alternative = "greater")
```

```
## 
## 	One Sample t-test
## 
## data:  sat.improve$sat_improve
## t = 9.0551, df = 29, p-value = 2.984e-10
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  110.4264      Inf
## sample estimates:
## mean of x 
##  135.9333
```

---
class: middle 
#### Two sided one-sample t test for means

`t.test` assumes the null hypothesis has `\(\mu=0\)`, but we can set other values as well:

** `\(H_0: \mu = 50\hspace{5ex} H_A:\mu\not=50\)` **


```r
# two-sided test
t.test(sat.improve$sat_improve, mu = 50)
```

```
## 
## 	One Sample t-test
## 
## data:  sat.improve$sat_improve
## t = 5.7244, df = 29, p-value = 3.401e-06
## alternative hypothesis: true mean is not equal to 50
## 95 percent confidence interval:
##  105.2308 166.6359
## sample estimates:
## mean of x 
##  135.9333
```

---
class: middle 
#### Hypothesis test for proportions

What if instead, we performed a hypothesis test about `\(p\)`, the proportion of students who improved?

** `\(H_0: p = 0.5\hspace{5ex} H_A:p &gt;0.5\)` **

```r
# 1. calculate sample statistic
p_hat &lt;- mean(sat.improve$sat_improve &gt; 0)
p_hat 
```

```
## [1] 0.9333333
```

```r
# 2. compute standard error
n &lt;- length(sat.improve$sat_improve)
se_p_hat &lt;- sqrt(p_hat * (1 - p_hat) / n)

# 3. compute t-statistic
z = (p_hat - 0.5) / se_p_hat
z
```

```
## [1] 9.515026
```
---
class: middle 
#### One-sided hypothesis test for proportions
** `\(H_0: p = 0.5\hspace{5ex} H_A:p &gt;0.5\)` **

Draw a picture: 
&lt;img src="lab-06_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;


```r
z = (p_hat - 0.5) / se_p_hat
# 4. calculate p-value
upper_tail_prob &lt;- 1 - pnorm(z)
upper_tail_prob
```

```
## [1] 0
```

---
class: middle 
#### Hypothesis test for proportions

What just happened?

The p-value is so small that R thinks it is essentially 0. 
---

class: middle 
#### 80% confidence interval for proportions


```r
# 80% z-interval
upper_bound &lt;- p_hat + qnorm(.90) * se_p_hat
lower_bound &lt;- p_hat - qnorm(.90) * se_p_hat
c(lower_bound, upper_bound)
```

```
## [1] 0.8749689 0.9916978
```
---
class: middle 
#### 95% confidence interval for proportions


```r
# 95% z-interval
upper_bound &lt;- p_hat + qnorm(.975) * se_p_hat
lower_bound &lt;- p_hat - qnorm(.975) * se_p_hat
c(lower_bound, upper_bound)
```

```
## [1] 0.8440726 1.0225940
```
---
class: middle 
#### 95% confidence interval for proportions
What just happened?

We tried to use the central limit theorem without checking to see if our sample size was big enough! We need `\(n\hat{p}\geq 10\)` and `\(n(1-\hat{p})\geq 10\)`. Which isn't satisfied? 
---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
